{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75edda21",
   "metadata": {},
   "source": [
    "# 大模型编码demo学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3faec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92aec0c",
   "metadata": {},
   "source": [
    "## 一、 使用阿里云百炼调用大模型 key base-url model\n",
    "注意：\n",
    "1. 在jupyter中似乎无法读环境变量，因此key使用明文，正常应该使用环境变量\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd237c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# 打印环境变量\n",
    "print(os.getenv(\"DASHSCOPE_API_KEY\"))\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    #打印环境变量\n",
    "    api_key=\"sk-730784af62d14bc6b5067a2e6633f096\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"你是谁？\"},\n",
    "    ],\n",
    "    # Qwen3模型通过enable_thinking参数控制思考过程（开源版默认True，商业版默认False）\n",
    "    # 使用Qwen3开源版模型时，若未启用流式输出，请将下行取消注释，否则会报错\n",
    "    # extra_body={\"enable_thinking\": False},\n",
    ")\n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc7269",
   "metadata": {},
   "source": [
    "## 二、 使用langchain调用大模型\n",
    "注意：\n",
    "1. 因为langchain升级很快，会有很多东西过时，学习教程中的导入包以及predict方法无法使用，需要时刻注意官网的更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b242ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "api_key=\"sk-730784af62d14bc6b5067a2e6633f096\"\n",
    "base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    temperature=0,\n",
    "    api_key=api_key, \n",
    "    base_url=base_url)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名字大师，请模仿实例起三个{country}名字，比如男孩名字经常叫做{boy_name}，女孩名字经常叫做{girl_name}\")\n",
    "message = prompt.format(country=\"中国特色的\", boy_name=\"高义\", girl_name=\"白洁\")\n",
    "\n",
    "print(message)\n",
    "response = llm.invoke(message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d9723",
   "metadata": {},
   "source": [
    "## 三、标准输出格式\n",
    "1. 可自定义输出解析器 继承BaseOutputParser\n",
    "2. temperature最好为0，防止模型输出格式的变化\n",
    "3. 用于对数据的格式清洗 todo 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac61abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo 标准输出格式\n",
    "# 1. 可自定义输出解析器 继承BaseOutputParser\n",
    "# 2. temperature最好为0，防止模型输出格式的变化\n",
    "# 3. 用于对数据的格式清洗 todo 代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fae5f",
   "metadata": {},
   "source": [
    "## 四、模型IO 大语言模型的交互接口\n",
    "- prompts ： 模版化\n",
    "- Language models ：LLM 和 chat model \n",
    "- Ourput parser ： 格式处理，比如处理为JSON和其他系统对接\n",
    "\n",
    "### prompts 模版 提示词提炼为模版，实现提示词的复用、版本管理、动态变化\n",
    "\n",
    "优秀提示词：\n",
    "- 角色：引导AI进入具体场景，赋予其身份\n",
    "- 问题：描述问题和困惑，以及背景信息\n",
    "- 目标：描述需求，希望达成的目标\n",
    "- 要求：告诉AI回答是注意什么，或者如何回复\n",
    "\n",
    "比如 ：我想去旅游，有什么建议？可以拓展为：\n",
    "我想旅游，请根据以下条件给我推荐几个目的地和行程安排：\n",
    "- 出发地：[你的城市]\n",
    "- 预计时间：[几天]，大致出发时间：[月份或节假日]\n",
    "- 预算：[金额范围]\n",
    "- 偏好：[自然风光 / 人文历史 / 海边度假 / 城市漫步 / 少人安静 等]\n",
    "- 出行方式：[飞机 / 高铁 / 自驾 / 无限制]\n",
    "- 同行人员：[一个人 / 情侣 / 家庭带小孩 / 老人 等]\n",
    "\n",
    "请给出推荐的目的地、适合的时间、交通方式、住宿建议和注意事项。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac36ac",
   "metadata": {},
   "source": [
    "### PromptTemplate 字符串模版，对应LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ede34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"What is the capital of {country}?\"\n",
    ")\n",
    "\n",
    "prompt.format_prompt(country=\"China\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060441b1",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate 对话模版具有结构，对应chat model\n",
    "- 角色 system user ai\n",
    "- 对话模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant,your name is {name}\"),\n",
    "    (\"user\", \"hello,{name}\"),\n",
    "    (\"ai\", \"hi\"),\n",
    "    (\"user\", \"What is the capital of {country}?\"),\n",
    "    (\"ai\", \"The capital of {country} is {capital}.\")\n",
    "])\n",
    "\n",
    "prompt.format_messages(country=\"China\", name=\"John\", capital=\"Beijing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70288d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "system_message = SystemMessage(content=\"You are a helpful assistant,your name is {name}\",additional_kwargs={\"name\":\"John\"})\n",
    "human_message = HumanMessage(content=\"hello,{name}\",additional_kwargs={\"name\":\"John\"})\n",
    "ai_message = AIMessage(content=\"hi\",additional_kwargs={\"name\":\"John\"})\n",
    "human_message = HumanMessage(content=\"What is the capital of {country}?\",additional_kwargs={\"country\":\"China\"})\n",
    "ai_message = AIMessage(content=\"The capital of {country} is {capital}.\",additional_kwargs={\"country\":\"China\",\"capital\":\"Beijing\"})\n",
    "\n",
    "messages = [system_message,human_message,ai_message,human_message,ai_message]\n",
    "\n",
    "print(messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da487af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatMessagePromptTemplate  role 自定义角色\n",
    "from unittest import result\n",
    "from langchain.prompts import AIMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"你真是个{subject}，{subject}真是个{subject}\"\n",
    "\n",
    "result = ChatMessagePromptTemplate.from_template(role=\"user\",template=prompt) \n",
    "\n",
    "result.format(subject=\"猪猪\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIMessagePromptTemplate \n",
    "from unittest import result\n",
    "from langchain.prompts import AIMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"你真是个{subject}，{subject}真是个{subject}\"\n",
    "\n",
    "result = AIMessagePromptTemplate.from_template(template=prompt) \n",
    "\n",
    "result.format(subject=\"猪猪\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9f3fd",
   "metadata": {},
   "source": [
    "### 自定义模版\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e6631",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 函数大师 ： 根据函数名称寻找函数，并给出中文说明\n",
    "\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "def hello_world():\n",
    "    print(\"hello world\")\n",
    "    return \"hello world\"\n",
    "\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验的程序员，现在给你如下函数，你会严格按照如下格式，输出这段代码的函数名称、源代码、中文解释。\n",
    "函数名称：{function_name}\n",
    "源代码：{source_code}\n",
    "中文解释：\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "# 自定义模版class\n",
    "\n",
    "\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # 获取函数源代码\n",
    "        source_code  = get_source_code(kwargs[\"function_name\"])\n",
    "        # 生成提示词模版\n",
    "        prompt = PROMPT.format(function_name=kwargs[\"function_name\"].__name__,source_code=source_code)\n",
    "        return prompt\n",
    "    \n",
    "a = CustomPromptTemplate(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "\n",
    "print(pm)\n",
    "\n",
    "# 和LLM交互\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "api_key=\"sk-730784af62d14bc6b5067a2e6633f096\"\n",
    "base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    temperature=0,\n",
    "    api_key=api_key, \n",
    "    base_url=base_url)\n",
    "\n",
    "response = llm.invoke(pm)\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa8a0c",
   "metadata": {},
   "source": [
    "### jinja2 与f-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebfa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f-string 格式化字符串 python内置的模版引擎\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "f_string = \"\"\"\n",
    "请给我讲一个关于{topic}的故事，故事要包含{topic}的{detail}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(f_string)\n",
    "\n",
    "print(prompt.format(topic=\"张三\",detail=\"身世\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jinjia2 模版引擎\n",
    "! pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef956fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jinjia2 模版引擎 更为灵活生成各种标记格式的文档\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "jinjia2_stirng = \"请给我讲一个关于{{topic}}的故事，故事要包含{{topic}}的{{detail}}\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(jinjia2_stirng,template_format=\"jinja2\")\n",
    "\n",
    "print(prompt.format(topic=\"张三\",detail=\"身世\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d4f29",
   "metadata": {},
   "source": [
    "### 三层提示词设计 性格-行为-禁止\n",
    "- 组合模版 \n",
    "- 多层模版 \n",
    "- Final prompt & Pipeline prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df126fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7180c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "你是一个经验丰富的程序员，你是中国人，住在北京。\n",
    "你总是穿格子衫。\n",
    "你从不说脏话。\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 子模板定义\n",
    "character_prompt = PromptTemplate.from_template(\"你是一个经验丰富的{person}，你是{country}人，住在{city}。\")\n",
    "behavior_prompt = PromptTemplate.from_template(\"你总是穿{clothes}。\")\n",
    "forbidden_prompt = PromptTemplate.from_template(\"你从不{forbidden}。\")\n",
    "\n",
    "# 最终模板\n",
    "final_prompt = PromptTemplate.from_template(\"\"\"\n",
    "{character}\n",
    "{behavior}\n",
    "{forbidden}\n",
    "\"\"\")\n",
    "\n",
    "# 模板列表\n",
    "pipeline_prompts = [\n",
    "    (\"character\", character_prompt),\n",
    "    (\"behavior\", behavior_prompt),\n",
    "    (\"forbidden\", forbidden_prompt)\n",
    "]\n",
    "\n",
    "# 输入参数\n",
    "input_values = {\n",
    "    \"person\": \"导游\",\n",
    "    \"country\": \"中国\",\n",
    "    \"city\": \"成都\",\n",
    "    \"clothes\": \"唐装\",\n",
    "    \"forbidden\": \"说脏话\"\n",
    "}\n",
    "\n",
    "# 用于保存每一层输出\n",
    "intermediate_values = {}\n",
    "\n",
    "# 使用循环逐步构建中间变量\n",
    "for name, prompt in pipeline_prompts:\n",
    "    intermediate_values[name] = prompt.format(**input_values)\n",
    "\n",
    "print(intermediate_values)\n",
    "\n",
    "# 最终生成完整提示\n",
    "final_result = final_prompt.format(**intermediate_values)\n",
    "\n",
    "# 输出\n",
    "print(final_result)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
